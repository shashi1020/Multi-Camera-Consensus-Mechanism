# cleaned_multicam_consensus.py
import os
import json
import hashlib
import argparse
from datetime import datetime
import time
import random
from collections import deque, defaultdict
import numpy as np
import cv2
from ultralytics import YOLO
import csv

# --- Logging paths (ensure directories exist) ---
OUT_IMG_DIR = "threat_logs/images"
CSV_DIR = "threat_logs/csv"
PER_FRAME_CSV = os.path.join(CSV_DIR, "per_frame_events.csv")
SUMMARY_CSV = os.path.join(CSV_DIR, "experiment_summary.csv")

os.makedirs(OUT_IMG_DIR, exist_ok=True)
os.makedirs(CSV_DIR, exist_ok=True)

# --- Helpers for saving images / CSV rows ---
def save_frame_image(img, run_id, cam_id, prefix="sus", max_width=640, quality=70):
    if img is None:
        return ""
    h, w = img.shape[:2]
    if w > max_width:
        scale = max_width / float(w)
        img = cv2.resize(img, (int(w*scale), int(h*scale)), interpolation=cv2.INTER_AREA)
    ts = datetime.utcnow().strftime("%Y%m%dT%H%M%S%f")[:-3]
    fn = f"{prefix}_{run_id}_cam{cam_id}_{ts}.jpg"
    path = os.path.join(OUT_IMG_DIR, fn)
    cv2.imwrite(path, img, [int(cv2.IMWRITE_JPEG_QUALITY), int(quality)])
    return path

# Ensure per-frame CSV header exists
if not os.path.exists(PER_FRAME_CSV):
    with open(PER_FRAME_CSV, "w", newline="") as fh:
        writer = csv.writer(fh)
        writer.writerow([
            "timestamp","run_id","frame_index","cam_id","image_path","hash",
            "threat_score","avg_uncertainty","disagreement","image_quality",
            "fallback_used","mitigation_type","num_consensus","num_validated",
            "per_camera_dets_json","consensus_json","notes"
        ])

def append_event_row(rowdict):
    row = [
        rowdict.get("timestamp",""),
        rowdict.get("run_id",""),
        rowdict.get("frame_index",""),
        rowdict.get("cam_id",""),
        rowdict.get("image_path",""),
        rowdict.get("hash",""),
        rowdict.get("threat_score",""),
        rowdict.get("avg_uncertainty",""),
        rowdict.get("disagreement",""),
        rowdict.get("image_quality",""),
        int(bool(rowdict.get("fallback_used", False))),
        rowdict.get("mitigation_type",""),
        rowdict.get("num_consensus",0),
        rowdict.get("num_validated",0),
        json.dumps(rowdict.get("per_camera_dets",[]), ensure_ascii=False),
        json.dumps(rowdict.get("consensus",[]), ensure_ascii=False),
        rowdict.get("notes","")
    ]
    with open(PER_FRAME_CSV, "a", newline="") as fh:
        writer = csv.writer(fh)
        writer.writerow(row)

# Ensure summary CSV exists
if not os.path.exists(SUMMARY_CSV):
    with open(SUMMARY_CSV, "w", newline="") as fh:
        writer = csv.writer(fh)
        writer.writerow([
            "run_id","method","seed","precision","recall","f1","map_50","map_5095",
            "avg_latency_ms","fallback_rate","ece","num_frames","num_suspicious","hardware","notes","date"
        ])

def append_summary_row(summary):
    row = [
        summary.get("run_id",""),
        summary.get("method",""),
        summary.get("seed",""),
        summary.get("precision",""),
        summary.get("recall",""),
        summary.get("f1",""),
        summary.get("map_50",""),
        summary.get("map_5095",""),
        summary.get("avg_latency_ms",""),
        summary.get("fallback_rate",""),
        summary.get("ece",""),
        summary.get("num_frames",""),
        summary.get("num_suspicious",""),
        summary.get("hardware",""),
        summary.get("notes",""),
        summary.get("date","")
    ]
    with open(SUMMARY_CSV, "a", newline="") as fh:
        writer = csv.writer(fh)
        writer.writerow(row)

# -------------------------
# Baseline Implementations
# -------------------------
def simple_average_fusion(camera_detections):
    fused = []
    all_dets = []
    for dets in camera_detections.values():
        all_dets.extend(dets)
    if not all_dets: return []
    classes = set(d['class_id'] for d in all_dets)
    for cls in classes:
        cls_dets = [d for d in all_dets if d['class_id']==cls]
        avg_conf = float(np.mean([d['confidence'] for d in cls_dets]))
        avg_bbox = np.mean([d['bbox'] for d in cls_dets], axis=0).tolist()
        fused.append({'class_id': cls, 'bbox': avg_bbox, 'confidence': avg_conf})
    return fused

def static_defense(camera_detections, preprocess_fn=lambda x: x):
    fused = {}
    for cam, dets in camera_detections.items():
        fused[cam] = []
        for d in dets:
            new_conf = min(d['confidence']*0.95, 1.0)
            fused[cam].append({'class_id': d['class_id'], 'bbox': d['bbox'], 'confidence': new_conf})
    return fused

def late_fusion(camera_detections, iou_thresh=0.5):
    fused = []
    all_dets = []
    for dets in camera_detections.values():
        all_dets.extend(dets)
    used = [False]*len(all_dets)
    def iou(a,b):
        xA = max(a[0], b[0]); yA = max(a[1], b[1])
        xB = min(a[2], b[2]); yB = min(a[3], b[3])
        interW = max(0, xB-xA); interH = max(0, yB-yA)
        if interW==0 or interH==0: return 0.0
        inter = interW*interH
        areaA = (a[2]-a[0])*(a[3]-a[1]); areaB = (b[2]-b[0])*(b[3]-b[1])
        union = areaA + areaB - inter
        return inter / union if union>0 else 0.0
    for i, d in enumerate(all_dets):
        if used[i]: continue
        group = [d]; used[i]=True
        for j, od in enumerate(all_dets[i+1:], start=i+1):
            if used[j]: continue
            if d['class_id'] != od['class_id']: continue
            if iou(d['bbox'], od['bbox']) > iou_thresh:
                group.append(od); used[j]=True
        avg_bbox = np.mean([g['bbox'] for g in group], axis=0).tolist()
        avg_conf = float(np.mean([g['confidence'] for g in group]))
        fused.append({'class_id': d['class_id'], 'bbox': avg_bbox, 'confidence': avg_conf})
    return fused

def run_baseline_tests(camera_detections, consensus_system, image_sizes, seeds=[42, 43, 44, 45, 46]):
    results = defaultdict(list)
    for seed in seeds:
        random.seed(seed)
        np.random.seed(seed)
        results['simple_avg'].append(simple_average_fusion(camera_detections))
        static_res = static_defense(camera_detections)
        merged_static = []
        for dets in static_res.values():
            merged_static.extend(dets)
        results['static_defense'].append(merged_static)
        results['late_fusion'].append(late_fusion(camera_detections))
        consensus_list, validated = consensus_system.process_detections(camera_detections, image_sizes)
        results['consensus'].append(consensus_list)
    return results

# -------------------------
# Config / Defaults
# -------------------------
THREAT_SCORE_THRESHOLD = 0.55
THREAT_LOG_DIR = "threat_logs"
os.makedirs(THREAT_LOG_DIR, exist_ok=True)
FALLBACK_MAX_LATENCY = 0.6
DEFAULT_CAM_PROBE_MAX = 4
DISPLAY_WINDOWS = False

# -------------------------
# Utilities
# -------------------------
def find_working_cameras(max_indices=DEFAULT_CAM_PROBE_MAX, width=640, height=480):
    good_caps = []
    cam_indices = []
    for i in range(max_indices):
        cap = cv2.VideoCapture(i, cv2.CAP_DSHOW)
        if not cap.isOpened():
            cap.release()
            continue
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
        time.sleep(0.15)
        ret, frame = cap.read()
        if not ret or frame is None:
            cap.release()
            continue
        good_caps.append(cap)
        cam_indices.append(i)
    return cam_indices, good_caps

# augment/draw helpers
def augment_image(image):
    flip = np.random.choice([True, False])
    angle = np.random.randint(-10, 10)
    brightness = np.random.uniform(0.5, 1.5)
    if flip:
        image = cv2.flip(image, 1)
    h, w = image.shape[:2]
    M = cv2.getRotationMatrix2D((w / 2, h / 2), angle, 1)
    image = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_LINEAR)
    image = cv2.convertScaleAbs(image, alpha=brightness, beta=0)
    return image

def draw_detections(img, detections, Box_colours, class_list):
    if img is None: return
    for det in detections:
        bb = det['bbox']
        clsID = det['class_id']
        conf = det['confidence']
        cv2.rectangle(img, (int(bb[0]), int(bb[1])), (int(bb[2]), int(bb[3])),
                    Box_colours[int(clsID)], 2)
        font = cv2.FONT_HERSHEY_SIMPLEX
        cv2.putText(img, f"{class_list[int(clsID)]} {conf:.2f}",
                    (int(bb[0]), int(bb[1]) - 6), font, 0.6, (255, 0, 255), 2)

# -------------------------
# Consensus class (unchanged)
# -------------------------
class IntelligentMultiCameraConsensus:
    def __init__(self,
                num_cameras,
                camera_positions=None,
                confidence_threshold=0.5,
                center_distance_threshold=0.12,
                temp_scale=1.2,
                history_len=6,
                min_persistence=2):
        self.num_cameras = num_cameras
        self.confidence_threshold = confidence_threshold
        self.camera_reliability_scores = np.ones(num_cameras, dtype=float)
        self.center_distance_threshold = center_distance_threshold
        self.temp_scale = temp_scale
        self.history = deque(maxlen=history_len)
        self.min_persistence = min_persistence
        self.camera_positions = camera_positions or {i: np.array([i, 0, 0], dtype=float) for i in range(num_cameras)}

    def process_detections(self, camera_detections, image_sizes):
        normalized = self._normalize_detections(camera_detections, image_sizes)
        self._calibrate_confidences(normalized)
        clusters = self._cluster_across_cameras(normalized)
        self._compute_spatial_support(clusters)
        consensus_list = self._make_consensus(clusters)
        validated = self._temporal_validation(consensus_list)
        self._update_camera_reliability(clusters, consensus_list)
        self.history.append(consensus_list)
        return consensus_list, validated

    def _normalize_detections(self, camera_detections, image_sizes):
        norm = {}
        for cam_id, dets in camera_detections.items():
            if cam_id not in image_sizes: continue
            w, h = image_sizes[cam_id]
            norm[cam_id] = []
            for d in dets:
                x1, y1, x2, y2 = d['bbox']
                cx = (x1 + x2) / 2.0 / w
                cy = (y1 + y2) / 2.0 / h
                nw = (x2 - x1) / w
                nh = (y2 - y1) / h
                norm[cam_id].append({
                    'orig': d,
                    'center': np.array([cx, cy]),
                    'size': np.array([nw, nh]),
                    'class_id': d['class_id'],
                    'confidence': d['confidence'],
                    'cam': cam_id
                })
        return norm

    def _calibrate_confidences(self, normalized):
        def temp_scale(conf):
            eps = 1e-6
            conf = np.clip(conf, eps, 1 - eps)
            logit = np.log(conf / (1 - conf))
            scaled = 1 / (1 + np.exp(-logit / self.temp_scale))
            return float(scaled)
        for cam_id, dets in normalized.items():
            for d in dets:
                d['confidence_cal'] = temp_scale(d['confidence'])

    def _cluster_across_cameras(self, normalized):
        clusters = []
        for cam_id, dets in normalized.items():
            for d in dets:
                placed = False
                for cl in clusters:
                    if d['class_id'] != cl['class_id']:
                        continue
                    centroid = cl['centroid']
                    dist = np.linalg.norm(d['center'] - centroid)
                    if dist <= self.center_distance_threshold:
                        cl['members'].append(d)
                        all_centers = np.array([m['center'] for m in cl['members']])
                        cl['centroid'] = np.mean(all_centers, axis=0)
                        placed = True
                        break
                if not placed:
                    clusters.append({'class_id': d['class_id'], 'members': [d], 'centroid': d['center'].copy()})
        return clusters

    def _compute_spatial_support(self, clusters):
        for cl in clusters:
            members = cl['members']
            n = len(members)
            if n <= 1:
                for m in members:
                    m['spatial_support'] = 0.0
                continue
            supports = []
            for i, mi in enumerate(members):
                s = 0.0
                for j, mj in enumerate(members):
                    if i == j: continue
                    center_dist = np.linalg.norm(mi['center'] - mj['center'])
                    center_score = np.exp(- (center_dist / (self.center_distance_threshold + 1e-6))**2)
                    size_diff = np.linalg.norm(mi['size'] - mj['size'])
                    size_score = 1.0 / (1.0 + size_diff*10.0)
                    pos_i = self.camera_positions[mi['cam']]
                    pos_j = self.camera_positions[mj['cam']]
                    cam_dist = np.linalg.norm(pos_i - pos_j)
                    geom_factor = 1.0 / (1.0 + cam_dist)
                    corr = center_score * size_score * geom_factor
                    s += corr
                s /= max(1, n-1)
                supports.append(s)
            for m, s in zip(members, supports):
                m['spatial_support'] = float(s)

    def _make_consensus(self, clusters):
        consensus_list = []
        for cl in clusters:
            members = cl['members']
            weights = []
            for m in members:
                cam_rel = float(self.camera_reliability_scores[m['cam']])
                weight = m.get('confidence_cal', m['confidence']) * cam_rel * (1.0 + m.get('spatial_support', 0.0))
                weights.append(weight)
            weights = np.array(weights) + 1e-8
            final_conf = float(np.sum([m.get('confidence_cal', m['confidence']) * w for m, w in zip(members, weights)]) / np.sum(weights))
            avg_sp = float(np.mean([m.get('spatial_support', 0.0) for m in members]))
            uncertainty = float(1.0 / (1.0 + avg_sp))
            consensus_strength = float(np.std(weights))
            per_camera_bboxes = defaultdict(lambda: None)
            for m in members:
                per_camera_bboxes[m['cam']] = m['orig']['bbox']
            consensus_list.append({
                'class_id': cl['class_id'],
                'final_confidence': final_conf,
                'uncertainty': uncertainty,
                'consensus_strength': consensus_strength,
                'members': members,
                'per_camera_bboxes': per_camera_bboxes,
            })
        return consensus_list

    def _temporal_validation(self, consensus_list):
        validated = []
        current_signatures = []
        for item in consensus_list:
            centroid = np.mean([m['center'] for m in item['members']], axis=0)
            current_signatures.append((item['class_id'], centroid))
        for idx, (cls, cent) in enumerate(current_signatures):
            count = 1
            for past in self.history:
                for p in past:
                    if p['class_id'] != cls:
                        continue
                    p_cent = np.mean([m['center'] for m in p['members']], axis=0)
                    if np.linalg.norm(p_cent - cent) <= self.center_distance_threshold:
                        count += 1
                        break
            if count >= self.min_persistence:
                validated.append(consensus_list[idx])
        return validated

    def _update_camera_reliability(self, clusters, consensus_list):
        decay = 0.995
        self.camera_reliability_scores *= decay
        for item in consensus_list:
            score = item['final_confidence'] * (1.0 - item['uncertainty'])
            for m in item['members']:
                cam = m['cam']
                self.camera_reliability_scores[cam] += 0.01 * score
        self.camera_reliability_scores = np.clip(self.camera_reliability_scores, 0.2, 2.0)

# -------------------------
# Threat assessor, TTA, ModelSwitcher, SuspiciousLogger
# -------------------------
def is_blurry(image, threshold=100.0):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    fm = cv2.Laplacian(gray, cv2.CV_64F).var()
    return fm < threshold, fm

def brightness_level(image):
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    return float(hsv[...,2].mean())

def hash_image(image):
    h = hashlib.sha256(image.tobytes()).hexdigest()[:10]
    return h

class ThreatAssessor:
    def __init__(self, weight_uncertainty=0.5, weight_disagreement=0.3, weight_image_quality=0.2):
        self.wu = weight_uncertainty
        self.wd = weight_disagreement
        self.wi = weight_image_quality

    def compute_disagreement(self, consensus_list, per_camera_detections):
        if len(consensus_list) == 0: return 0.0
        disagreements = []
        num_cams = max(1, len(per_camera_detections))
        for item in consensus_list:
            cams_present = sum(1 for c in item['per_camera_bboxes'].keys() if item['per_camera_bboxes'][c] is not None)
            frac_missing = 1.0 - (cams_present / num_cams)
            disagreements.append(frac_missing)
        return float(np.mean(disagreements)) if disagreements else 0.0

    def compute_threat(self, consensus_list, per_camera_detections, frames):
        if len(consensus_list) == 0:
            avg_unc = 0.0
        else:
            avg_unc = float(np.mean([it.get('uncertainty', 1.0) for it in consensus_list]))
        disagreement = self.compute_disagreement(consensus_list, per_camera_detections)
        blur_vals = []
        bright_vals = []
        for cam, im in frames.items():
            if im is None: continue
            blurry, fm = is_blurry(im)
            blur_vals.append(1.0 - min(fm/200.0, 1.0))
            bright_vals.append(abs(brightness_level(im) / 255.0 - 0.5) * 2.0)
        image_quality_score = float(np.mean(blur_vals + bright_vals)) if (blur_vals or bright_vals) else 0.0
        threat_score = (self.wu * avg_unc) + (self.wd * disagreement) + (self.wi * image_quality_score)
        threat_score = float(np.clip(threat_score, 0.0, 1.0))
        meta = {'avg_uncertainty': avg_unc, 'disagreement': disagreement, 'image_quality': image_quality_score,
                'per_camera_blur': blur_vals, 'per_camera_brightness_extremes': bright_vals}
        return threat_score, meta

def jpeg_recompress(image, quality=70):
    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), int(quality)]
    result, encimg = cv2.imencode('.jpg', image, encode_param)
    if not result:
        return image
    decimg = cv2.imdecode(encimg, 1)
    return decimg

def median_denoise(image, ksize=3):
    return cv2.medianBlur(image, ksize)

def test_time_augment_ensemble(model, image, augment_fns=None, conf=0.45):
    if augment_fns is None:
        augment_fns = [lambda x: x, lambda x: cv2.flip(x, 1), lambda x: cv2.GaussianBlur(x, (3,3), 0)]
    all_preds = []
    for fn in augment_fns:
        im2 = fn(image)
        det_raw = model.track(source=[im2], conf=conf, save=False)
        if len(det_raw[0]) > 0:
            for b in det_raw[0].boxes:
                bb = b.xyxy.numpy()[0].copy()
                confv = float(b.conf.numpy()[0])
                cls = int(b.cls.numpy()[0])
                all_preds.append({'bbox': bb, 'confidence': confv, 'class_id': cls})
    merged = []
    used = [False]*len(all_preds)
    def iou(a,b):
        xA = max(a[0], b[0]); yA = max(a[1], b[1])
        xB = min(a[2], b[2]); yB = min(a[3], b[3])
        interW = max(0, xB-xA); interH = max(0, yB-yA)
        if interW==0 or interH==0: return 0.0
        inter = interW*interH
        areaA = (a[2]-a[0])*(a[3]-a[1]); areaB = (b[2]-b[0])*(b[3]-b[1])
        union = areaA + areaB - inter
        return inter / union if union>0 else 0.0
    for i,p in enumerate(all_preds):
        if used[i]: continue
        group = [p]; used[i]=True
        for j,q in enumerate(all_preds[i+1:], start=i+1):
            if used[j]: continue
            if p['class_id'] != q['class_id']: continue
            if iou(p['bbox'], q['bbox']) > 0.5:
                group.append(q); used[j] = True
        avg_conf = float(np.mean([g['confidence'] for g in group]))
        avg_box = np.mean(np.array([g['bbox'] for g in group]), axis=0)
        merged.append({'bbox': avg_box.tolist(), 'confidence': avg_conf, 'class_id': group[0]['class_id']})
    return merged

class ModelSwitcher:
    def __init__(self, fast_model, robust_model=None):
        self.fast = fast_model
        self.robust = robust_model
        self.fallback_count = 0
    def infer_raw(self, image, use_robust=False, conf=0.45):
        if use_robust and self.robust is not None:
            self.fallback_count += 1
            t0 = time.time()
            preds = self.robust.track(source=[image], conf=conf, save=False)
            latency = time.time() - t0
            return preds, latency, 'robust'
        else:
            t0 = time.time()
            preds = self.fast.track(source=[image], conf=conf, save=False)
            latency = time.time() - t0
            return preds, latency, 'fast'
    def infer_detection_dict(self, image, use_robust=False, conf=0.45):
        det_raw, latency, tag = self.infer_raw(image, use_robust=use_robust, conf=conf)
        dets = []
        if len(det_raw[0]) > 0:
            for b in det_raw[0].boxes:
                bb = b.xyxy.numpy()[0].copy()
                confv = float(b.conf.numpy()[0])
                cls = int(b.cls.numpy()[0])
                dets.append({'bbox': bb, 'confidence': confv, 'class_id': cls})
        return dets, latency, tag

class SuspiciousLogger:
    def __init__(self, outdir=THREAT_LOG_DIR):
        self.outdir = outdir

    def log(self, frames, consensus_list, meta, threat_score,
            run_id="run", frame_index=0, per_camera_dets=None, fallback_used=False):
        ts = datetime.utcnow().isoformat()
        image_paths = {}
        hashes = {}
        for cam_id, img in frames.items():
            if img is None:
                image_paths[cam_id] = None
                hashes[cam_id] = None
                continue
            p = save_frame_image(img, run_id, cam_id, prefix="sus", max_width=640, quality=70)
            image_paths[cam_id] = p
            hashes[cam_id] = hash_image(img)

        per_cam_summary = {}
        if isinstance(per_camera_dets, dict):
            for cam_id, dets in per_camera_dets.items():
                small = []
                for d in dets:
                    # robustly extract bbox (list / tuple / numpy array / None)
                    raw_bbox = d.get("bbox", None)
                    if raw_bbox is None:
                        bbox_list = []
                    elif isinstance(raw_bbox, (list, tuple)):
                        bbox_list = [float(x) for x in raw_bbox]
                    else:
                        # try to convert numpy arrays or similar
                        try:
                            bbox_list = [float(x) for x in np.asarray(raw_bbox).reshape(-1).tolist()]
                        except Exception:
                            bbox_list = []
                    small.append({
                        "class_id": int(d.get("class_id", -1)),
                        "confidence": float(d.get("confidence", 0.0)),
                        "bbox": bbox_list
                    })
                per_cam_summary[int(cam_id)] = small


        consensus_compact = []
        for it in consensus_list:
            per_cam_bbs = {int(k): (v.tolist() if v is not None else None) for k, v in it.get("per_camera_bboxes", {}).items()}
            consensus_compact.append({
                "class_id": int(it.get("class_id", -1)),
                "final_confidence": float(it.get("final_confidence", 0.0)),
                "uncertainty": float(it.get("uncertainty", 0.0)),
                "consensus_strength": float(it.get("consensus_strength", 0.0)),
                "per_camera_bboxes": per_cam_bbs
            })

        row = {
            "timestamp": ts,
            "run_id": run_id,
            "frame_index": frame_index,
            "cam_id": None,
            "image_path": json.dumps(image_paths),
            "hash": json.dumps(hashes),
            "threat_score": float(threat_score),
            "avg_uncertainty": meta.get("avg_uncertainty", None),
            "disagreement": meta.get("disagreement", None),
            "image_quality": meta.get("image_quality", None),
            "fallback_used": bool(fallback_used),
            "mitigation_type": meta.get("mitigation", ""),
            "num_consensus": len(consensus_list),
            "num_validated": len([1 for _ in consensus_list if _ is not None]),
            "per_camera_dets": per_cam_summary,
            "consensus": consensus_compact,
            "notes": ""
        }

        append_event_row(row)

        # optional JSON meta
        try:
            out_meta_path = os.path.join(self.outdir, f"{run_id}_{frame_index}_meta.json")
            with open(out_meta_path, "w") as fh:
                json.dump({"timestamp": ts,
                           "threat_score": float(threat_score),
                           "meta": meta,
                           "image_paths": image_paths,
                           "consensus": consensus_compact,
                           "per_camera_dets": per_cam_summary}, fh, indent=2)
        except Exception:
            pass

        return image_paths

# -------------------------
# Main runnable loop
# -------------------------
def main(args):
    # Load class list
    with open(args.class_list) as f:
        class_list = f.read().strip().split("\n")
    Box_colours = []
    for i in range(len(class_list)):
        Box_colours.append((random.randint(0,255), random.randint(0,255), random.randint(0,255)))

    print("Loading fast model:", args.fast_model)
    fast_model = YOLO(args.fast_model)
    robust_model = None
    if args.robust_model:
        try:
            print("Loading robust model:", args.robust_model)
            robust_model = YOLO(args.robust_model)
        except Exception as e:
            print("Could not load robust model:", e)
            robust_model = None

    model_switcher = ModelSwitcher(fast_model=fast_model, robust_model=robust_model)
    threat_assessor = ThreatAssessor()
    slogger = SuspiciousLogger()

    # Camera or videos
    cam_indices = []
    caps = []
    video_paths = [
        r"E:\\WEOPEN DETECTION RESEARCH PAPER\\Project Coding\\Real_Time_weopen_Detection.py\\test0.mp4",
        r"E:\\WEOPEN DETECTION RESEARCH PAPER\\Project Coding\\Real_Time_weopen_Detection.py\\test1.mp4",
        r"E:\\WEOPEN DETECTION RESEARCH PAPER\\Project Coding\\Real_Time_weopen_Detection.py\\test2.mp4"
    ]
    if args.video_paths:
        for idx, p in enumerate(video_paths):
            cap = cv2.VideoCapture(p)
            if not cap.isOpened():
                print(f"Failed to open video: {p}")
                continue
            caps.append(cap)
            cam_indices.append(idx)
    else:
        if len(caps) == 0:
            print("No cameras found. Exiting.")
            return

    num_cams = len(caps)
    camera_positions = {i: np.array([float(i), 0.0, 0.0]) for i in range(num_cams)}
    consensus_system = IntelligentMultiCameraConsensus(num_cameras=num_cams, camera_positions=camera_positions,
                                                    confidence_threshold=0.5, center_distance_threshold=0.12,
                                                    temp_scale=1.2, history_len=6, min_persistence=2)
    print(f"Using {num_cams} camera(s):", cam_indices)

    # bookkeeping
    run_id = f"run_{datetime.utcnow().strftime('%Y%m%dT%H%M%S')}"
    num_frames = 0
    num_suspicious = 0
    total_inference_latency = 0.0
    inference_count = 0

    try:
        frame_count = 0
        MAX_FRAMES = 500
        finished = [False] * len(caps)
        while not all(finished) and frame_count < MAX_FRAMES:
            # increment frame counters
            frame_count += 1
            num_frames += 1

            frames = {}
            image_sizes = {}
            # read all frames
            for cam_pos, cap in enumerate(caps):
                if finished[cam_pos]:
                    frames[cam_pos] = None
                    continue
                ret, frame = cap.read()
                if not ret or frame is None:
                    frames[cam_pos] = None
                    finished[cam_pos] = True
                else:
                    frames[cam_pos] = frame
                    h, w = frame.shape[:2]
                    image_sizes[cam_pos] = (w, h)

            if all(fr is None for fr in frames.values()):
                print("All frames empty; ending.")
                break

            # Per-camera detection collect (use augmentation during inference lightly)
            camera_detections = {}
            for cam_pos, frame in frames.items():
                if frame is None:
                    camera_detections[cam_pos] = []
                    continue
                aug = augment_image(frame) if args.augment_inference else frame
                dets, lat, tag = model_switcher.infer_detection_dict(aug, use_robust=False, conf=args.conf)
                camera_detections[cam_pos] = dets
                total_inference_latency += float(lat)
                inference_count += 1

            baseline_results = run_baseline_tests(camera_detections, consensus_system, image_sizes)
            for k, v in baseline_results.items():
                print(f"{k}: {len(v)} runs collected")

            # Visualize per-camera raw detections
            for cam_pos, frame in frames.items():
                if frame is None: continue
                draw_detections(frame, camera_detections[cam_pos], Box_colours, class_list)

            # Consensus
            consensus_list, validated = consensus_system.process_detections(camera_detections, image_sizes)

            # Overlay consensus info on frames
            for item in consensus_list:
                cls = item['class_id']; conf = item['final_confidence']; unc = item['uncertainty']
                for cam_id in range(num_cams):
                    frm = frames.get(cam_id)
                    if frm is None: continue
                    txt = f"C:{class_list[cls]} Conf:{conf:.2f} Unc:{unc:.2f}"
                    cv2.putText(frm, txt, (10, 30 + 20 * cam_id), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)
                    if cam_id in item['per_camera_bboxes'] and item['per_camera_bboxes'][cam_id] is not None:
                        bb = item['per_camera_bboxes'][cam_id]
                        cv2.rectangle(frm, (int(bb[0]), int(bb[1])), (int(bb[2]), int(bb[3])), (0,255,0), 3)

            # Threat assessment
            # Threat assessment
            threat_score, threat_meta = threat_assessor.compute_threat(consensus_list, camera_detections, frames)
            # debug print so you see values each frame
            print(f"[FRAME {frame_count}] threat_score={threat_score:.3f} meta={threat_meta}")

            # initialize fallback flag
            fallback_used = False

            # if requested, always log per-frame (debug mode), otherwise log only suspicious frames
            should_log = (threat_score >= THREAT_SCORE_THRESHOLD) or getattr(args, "log_all_frames", False)
            if should_log:
                if threat_score >= THREAT_SCORE_THRESHOLD:
                    num_suspicious += 1
                slog_path = slogger.log(frames, consensus_list, threat_meta, threat_score,
                                        run_id=run_id, frame_index=frame_count,
                                        per_camera_dets=camera_detections,
                                        fallback_used=fallback_used)

            # If suspicious => mitigation + optional fallback consensus re-run
            if threat_score >= THREAT_SCORE_THRESHOLD:
                # Preprocess frames quickly
                pre_frames = {cid: (jpeg_recompress(frames[cid], quality=70) if frames[cid] is not None else None) for cid in frames}
                replaced_camera_dets = {}

                if robust_model is not None:
                    latencies = []
                    for cam_pos, pf in pre_frames.items():
                        if pf is None:
                            replaced_camera_dets[cam_pos] = []
                            continue
                        dets, lat, tag = model_switcher.infer_detection_dict(pf, use_robust=True, conf=args.conf)
                        latencies.append(lat)
                        replaced_camera_dets[cam_pos] = dets
                    avg_lat = np.mean(latencies) if latencies else 0.0
                    if avg_lat <= FALLBACK_MAX_LATENCY:
                        fallback_used = True
                        for cam_pos, frm in frames.items():
                            if frm is None: continue
                            cv2.putText(frm, f"MITIGATED: FALLBACK (score {threat_score:.2f})", (10,20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)
                        camera_detections = replaced_camera_dets
                        consensus_list, validated = consensus_system.process_detections(camera_detections, image_sizes)
                    else:
                        for cam_pos, pf in pre_frames.items():
                            if pf is None:
                                replaced_camera_dets[cam_pos] = []
                                continue
                            tta_dets = test_time_augment_ensemble(fast_model, pf, augment_fns=None, conf=args.conf)
                            replaced_camera_dets[cam_pos] = tta_dets
                        camera_detections = replaced_camera_dets
                        consensus_list, validated = consensus_system.process_detections(camera_detections, image_sizes)
                        for cam_pos, frm in frames.items():
                            if frm is None: continue
                            cv2.putText(frm, f"MITIGATED: TTA (score {threat_score:.2f})", (10,20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,165,255), 2)
                else:
                    for cam_pos, pf in pre_frames.items():
                        if pf is None:
                            replaced_camera_dets[cam_pos] = []
                            continue
                        tta_dets = test_time_augment_ensemble(fast_model, pf, augment_fns=None, conf=args.conf)
                        replaced_camera_dets[cam_pos] = tta_dets
                    camera_detections = replaced_camera_dets
                    consensus_list, validated = consensus_system.process_detections(camera_detections, image_sizes)
                    for cam_pos, frm in frames.items():
                        if frm is None: continue
                        cv2.putText(frm, f"MITIGATED: PREPROCESS/TTA (score {threat_score:.2f})", (10,20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,165,255), 2)

                # draw consensus after mitigation (keeps behavior)
                for item in consensus_list:
                    cls = item['class_id']; conf = item['final_confidence']; unc = item['uncertainty']
                    for cam_id in range(num_cams):
                        frm = frames.get(cam_id)
                        if frm is None: continue
                        txt = f"AFTER C:{class_list[cls]} Conf:{conf:.2f} Unc:{unc:.2f}"
                        cv2.putText(frm, txt, (10, 50 + 20 * cam_id), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255,255,0), 2)


                # Preprocess frames quickly
                pre_frames = {cid: (jpeg_recompress(frames[cid], quality=70) if frames[cid] is not None else None) for cid in frames}
                replaced_camera_dets = {}

                if robust_model is not None:
                    latencies = []
                    for cam_pos, pf in pre_frames.items():
                        if pf is None:
                            replaced_camera_dets[cam_pos] = []
                            continue
                        dets, lat, tag = model_switcher.infer_detection_dict(pf, use_robust=True, conf=args.conf)
                        latencies.append(lat)
                        replaced_camera_dets[cam_pos] = dets
                    avg_lat = np.mean(latencies) if latencies else 0.0
                    if avg_lat <= FALLBACK_MAX_LATENCY:
                        fallback_used = True
                        for cam_pos, frm in frames.items():
                            if frm is None: continue
                            cv2.putText(frm, f"MITIGATED: FALLBACK (score {threat_score:.2f})", (10,20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)
                        camera_detections = replaced_camera_dets
                        consensus_list, validated = consensus_system.process_detections(camera_detections, image_sizes)
                    else:
                        for cam_pos, pf in pre_frames.items():
                            if pf is None:
                                replaced_camera_dets[cam_pos] = []
                                continue
                            tta_dets = test_time_augment_ensemble(fast_model, pf, augment_fns=None, conf=args.conf)
                            replaced_camera_dets[cam_pos] = tta_dets
                        camera_detections = replaced_camera_dets
                        consensus_list, validated = consensus_system.process_detections(camera_detections, image_sizes)
                        for cam_pos, frm in frames.items():
                            if frm is None: continue
                            cv2.putText(frm, f"MITIGATED: TTA (score {threat_score:.2f})", (10,20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,165,255), 2)
                else:
                    for cam_pos, pf in pre_frames.items():
                        if pf is None:
                            replaced_camera_dets[cam_pos] = []
                            continue
                        tta_dets = test_time_augment_ensemble(fast_model, pf, augment_fns=None, conf=args.conf)
                        replaced_camera_dets[cam_pos] = tta_dets
                    camera_detections = replaced_camera_dets
                    consensus_list, validated = consensus_system.process_detections(camera_detections, image_sizes)
                    for cam_pos, frm in frames.items():
                        if frm is None: continue
                        cv2.putText(frm, f"MITIGATED: PREPROCESS/TTA (score {threat_score:.2f})", (10,20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,165,255), 2)

                # draw consensus after mitigation
                for item in consensus_list:
                    cls = item['class_id']; conf = item['final_confidence']; unc = item['uncertainty']
                    for cam_id in range(num_cams):
                        frm = frames.get(cam_id)
                        if frm is None: continue
                        txt = f"AFTER C:{class_list[cls]} Conf:{conf:.2f} Unc:{unc:.2f}"
                        cv2.putText(frm, txt, (10, 50 + 20 * cam_id), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255,255,0), 2)

            # validated overlays
            for item in validated:
                for cam_id in range(num_cams):
                    frm = frames.get(cam_id)
                    if frm is None: continue
                    cv2.putText(frm, "VALIDATED", (10, 80 + 20 * cam_id), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,165,255), 2)

            # show frames
            if DISPLAY_WINDOWS:
                for cam_pos, frame in frames.items():
                    if frame is None:
                        continue
                    cv2.imshow(f'Camera {cam_pos}', frame)
                if cv2.waitKey(1) == ord('q'):
                    break

    finally:
        for c in caps:
            c.release()
        if DISPLAY_WINDOWS:
            cv2.destroyAllWindows()

        # compute simple run summary
        avg_latency_ms = (total_inference_latency / inference_count * 1000.0) if inference_count > 0 else 0.0
        fallback_rate = (model_switcher.fallback_count / max(1, num_frames)) if num_frames > 0 else 0.0
        summary = {
            "run_id": run_id,
            "method": os.path.basename(args.fast_model),
            "seed": "",
            "precision": "",
            "recall": "",
            "f1": "",
            "map_50": "",
            "map_5095": "",
            "avg_latency_ms": float(avg_latency_ms),
            "fallback_rate": float(fallback_rate),
            "ece": "",
            "num_frames": int(num_frames),
            "num_suspicious": int(num_suspicious),
            "hardware": "",
            "notes": "",
            "date": datetime.utcnow().isoformat()
        }
        append_summary_row(summary)
        print(f"Summary row appended to {SUMMARY_CSV}")

# -------------------------
# CLI
# -------------------------
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Adaptive Multi-Camera Consensus Demo")
    parser.add_argument("--fast-model", type=str, default="3339model/weights/best.pt", help="Fast YOLO model path")
    parser.add_argument("--robust-model", type=str, default="3339model/weights/last.pt", help="Robust YOLO model path (optional)")
    parser.add_argument("--class-list", type=str, default="utils/coco.txt", help="Class list file")
    parser.add_argument("--max-cam-probing", type=int, default=4, help="max camera indices to probe")
    parser.add_argument("--conf", type=float, default=0.45, help="detection confidence threshold")
    parser.add_argument("--video-paths", nargs="*", help="optional video files instead of live cameras")
    parser.add_argument("--augment-inference", action="store_true", help="apply light augmentation before inference")
    args = parser.parse_args()
    if not args.video_paths:
        args.video_paths = [
            r"E:\WEOPEN DETECTION RESEARCH PAPER\\Project Coding\\Real_Time_weopen_Detection.py\\test0.mp4",
            r"E:\WEOPEN DETECTION RESEARCH PAPER\\Project Coding\\Real_Time_weopen_Detection.py\\test1.mp4",
            r"E:\WEOPEN DETECTION RESEARCH PAPER\\Project Coding\\Real_Time_weopen_Detection.py\\test2.mp4"
        ]
    main(args)
